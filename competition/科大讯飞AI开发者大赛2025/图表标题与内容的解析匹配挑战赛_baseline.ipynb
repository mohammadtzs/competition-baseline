{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842a4c47-52ef-4fd2-87ab-2e8e6c3ccb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 20:40:37.450943: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "model = CLIPModel.from_pretrained(\"/home/lyz/hf-models/openai/clip-vit-base-patch16\")\n",
    "processor = CLIPProcessor.from_pretrained(\"/home/lyz/hf-models/openai/clip-vit-base-patch16\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9212c81-402b-48e7-893d-efbf6c77b2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/81ab3d22-0ae8-4c76-8f91-55757ec4678a...</td>\n",
       "      <td>step-wise select prompt to select next step.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/90a408aa-dbbf-4ade-a9c9-32abbf57f7e8...</td>\n",
       "      <td>Generated Persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/0e6e79e6-6fd4-4911-bc45-dcb272e80beb...</td>\n",
       "      <td>Failure analysis across the four methods on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/bedcf7d3-a91c-4c3b-b266-9c4a24efa24c...</td>\n",
       "      <td>TTS case of Scoring Bias.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/de788cb6-6929-4152-8795-84208728ec9c...</td>\n",
       "      <td>3D trajectory plot plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>./dataset/891f4550-4db7-4c2c-9d02-db3037f92c29...</td>\n",
       "      <td>DeepSeekV3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>./dataset/c610fb41-26ff-4ac7-a586-d86465144134...</td>\n",
       "      <td>Overview of the survey presented in this work.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>./dataset/ffe09dee-7de4-4400-80fa-59df54d3bdb7...</td>\n",
       "      <td>Distribution of ``All Passed Code'' (code that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>./dataset/8c8e591d-d430-4c00-a36b-32f025aa181c...</td>\n",
       "      <td>Input and Output Token Cost across Various LLM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>./dataset/3205faf7-3509-4e57-ab8c-c1b119dd6729...</td>\n",
       "      <td>GPT 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Source  \\\n",
       "0     ./dataset/81ab3d22-0ae8-4c76-8f91-55757ec4678a...   \n",
       "1     ./dataset/90a408aa-dbbf-4ade-a9c9-32abbf57f7e8...   \n",
       "2     ./dataset/0e6e79e6-6fd4-4911-bc45-dcb272e80beb...   \n",
       "3     ./dataset/bedcf7d3-a91c-4c3b-b266-9c4a24efa24c...   \n",
       "4     ./dataset/de788cb6-6929-4152-8795-84208728ec9c...   \n",
       "...                                                 ...   \n",
       "1402  ./dataset/891f4550-4db7-4c2c-9d02-db3037f92c29...   \n",
       "1403  ./dataset/c610fb41-26ff-4ac7-a586-d86465144134...   \n",
       "1404  ./dataset/ffe09dee-7de4-4400-80fa-59df54d3bdb7...   \n",
       "1405  ./dataset/8c8e591d-d430-4c00-a36b-32f025aa181c...   \n",
       "1406  ./dataset/3205faf7-3509-4e57-ab8c-c1b119dd6729...   \n",
       "\n",
       "                                                Caption  \n",
       "0          step-wise select prompt to select next step.  \n",
       "1                                     Generated Persona  \n",
       "2     Failure analysis across the four methods on th...  \n",
       "3                             TTS case of Scoring Bias.  \n",
       "4                               3D trajectory plot plot  \n",
       "...                                                 ...  \n",
       "1402                                         DeepSeekV3  \n",
       "1403     Overview of the survey presented in this work.  \n",
       "1404  Distribution of ``All Passed Code'' (code that...  \n",
       "1405  Input and Output Token Cost across Various LLM...  \n",
       "1406                                              GPT 4  \n",
       "\n",
       "[1407 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "df = pd.read_csv(\"sample_submit.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3de722c6-edf8-47b7-b0c3-bd12f4b83eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for path in df[\"Source\"].values:\n",
    "    try:\n",
    "        if path.endswith(\"pdf\"):\n",
    "            with pdfplumber.open(path) as pdf:\n",
    "                first_page = pdf.pages[0]\n",
    "                im = first_page.to_image(resolution=150).original\n",
    "        else:\n",
    "            im = Image.open(path)\n",
    "    except:\n",
    "        im = Image.open(\"./dataset/01a882f1-8a14-4421-8094-6f363a195971.png\")\n",
    "    images.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e556815d-7ffd-46fe-8f6a-995131f0a4b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyz/anaconda3/envs/py311/lib/python3.11/site-packages/PIL/Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image_embeds = []\n",
    "for idx in range(len(images) // 20 + 1):\n",
    "    inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=images[idx*20:(idx+1)*20], return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    image_embeds.append(outputs.image_embeds.data.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "711d1ce5-d15f-4833-8e85-e47e183b9db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "text_embeds = []\n",
    "for idx in range(len(df[\"Caption\"].values) // 20 + 1):\n",
    "    inputs = processor(text=list([x[:100] for x in df[\"Caption\"].values[idx*20:(idx+1)*20]]), images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    text_embeds.append(outputs.text_embeds.data.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aab92ab8-87c4-4a04-8a85-c68d84e62295",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeds = np.vstack(image_embeds)\n",
    "text_embeds = np.vstack(text_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66c8f33b-e115-4f60-978a-6803023c8718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1407, 512), (1407, 512))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeds.shape, text_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4193e95-97d3-4db0-ba0b-9d00b8fa35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "image_embeds = normalize(image_embeds)\n",
    "text_embeds = normalize(text_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "551c72cc-b5fe-4e8f-9833-74e5e9c6337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_preds = []\n",
    "for image_embed in image_embeds:\n",
    "    clip_preds.append(df[\"Caption\"].values[np.argmax(np.dot(image_embed, text_embeds.T))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a633e70-2887-4606-928c-9cabdc7b88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Caption'] = clip_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39690f69-4214-46bc-954f-1613caadf736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"submit.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84504d-ea0c-4a93-8111-2f5642c05449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
